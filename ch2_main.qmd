---
title: "Three-dimensional data of wire-cut surface scans under the confocal microscope (110 character maximum, inc. spaces)"
authors: 
  - name: Yuhang Lin
    affiliations:
      - ref: 1
      - ref: 2
    orcid: 0000-0002-3600-9889
    email: yhlin@iastate.edu
    corresponding: true
  - name: Heike Hofmann
    affiliations:
      - ref: 2
      - ref: 3
    orcid: 0000-0001-6216-5183
    email: hhofmann4@unl.edu
    corresponding: false
  - name: Curtis Mosher
    affiliations:
      - ref: 4
    email: cmosher@iastate.edu
    corresponding: false
  - name: Eden Amin
    affiliations:
      - ref: 5
    email: eamin@iastate.edu
    corresponding: false
  - name: Jeff Salyards
    affiliations:
      - ref: 2
    orcid: 0000-0002-8321-1246
    email: jdsal@msn.com
    corresponding: false
  - name: Alicia Carriquiry
    affiliations:
      - ref: 1
      - ref: 2
    orcid: 0000-0002-6428-9427
    email: alicia@iastate.edu
    corresponding: false
affiliations: 
  - id: 1
    name: Iowa State University
    department: Department of Statistics
    city: Ames, IA, 50011
    country: USA
  - id: 2
    name: Iowa State University
    department: Center for Statistics and Applications in Forensic Evidence (CSAFE)
    city: Ames, IA, 50011
    country: USA
  - id: 3
    name: University of Nebraska-Lincoln
    department: Department of Statistics
    city: Lincoln, NE, 68583
    country: USA
  - id: 4
    name: Iowa State University
    department: Roy J Carver High Resolution Microscopy Facility (HRMF)
    city: Ames, IA, 50011
    country: USA
  - id: 5
    name: University of Central Oklahoma
    department: Criminal Justice and Forensic Science
    city: Edmond, OK, 73034
    country: USA
abstract: |
 \tom{Update later: max of 170 words: describe the study, the assay(s) performed,  resulting data, and reuse potential}
 Wire cut data is important in forensic investigations but lacks a systematic way of analyzing the data.
 We created a data set of 120 scans of aluminum wire cut in \texttt{x3p} format,
 using 5 wire cutters and 3 locations along the 4 blades,
 with 2 replicates for each combination.
 A systematic pipeline with multiple analysis plots was developed to analyze the data and draw conclusions based on numerical measures.
number-sections: false
format:
  pdf:
    cite-method: natbib
    template: sf_template.tex
    keep-tex: true
bibliography: "`r rbbt::bbt_write_bib('references.bib', ignore = stringr::str_subset(rbbt::bbt_detect_citations(), '(^fig-|^tbl-|^eq-|^sec-|^lst-|^thm-|^lem-|^cor-|^prp-|^cnj-|^def-|^exm-|^exr-)'), overwrite = TRUE, library_id=rbbt::bbt_library_id('CSAFE'), translator='bibtex')`"
acknowledgements: |
 This work was partially funded by the Center for Statistics and Applications in Forensic Evidence (CSAFE) through Cooperative Agreement 70NANB20H019 between NIST and Iowa State University, which includes activities carried out at Carnegie Mellon University, Duke University, University of California Irvine, University of Virginia, West Virginia University, University of Pennsylvania, Swarthmore College and the University of Nebraska-Lincoln.
contributions: |
 \hh{Let's follow the Elsevier definitions: https://www.elsevier.com/researcher/author/policies-and-guidelines/credit-author-statement}
 Y.L.: Methodology, Software, Validation, Data Curation, Writing - Draft; H.H.: Conceptualization, Methodology, Validation, Writing - Review & Editing; C.M.: Lab supervision;
 E.A.: Physical Specimen, Scanning; J.S: Forensic advice; A.C.: Funding acquisition.
competing: |
 H.H. is a technical advisor to AFTE (Association of Firearms and Toolmarks Examiners), fellow of the ASA (American Statistical Association), and committee member of the ASA Forensic Science Committee. H.H. has testified as court witness on behalf of judge April Neubauer, NY State Supreme Court Criminal Term in New York City. 
 \hh{other competing interests - Alicia?}
editor_options: 
  chunk_output_type: console
---


```{r}
#| include: FALSE
#| eval: true

set.seed(0)

library(tidyverse)

library(gt) # for tables
```



```{r eval=FALSE, echo=FALSE}
# re-run to update references
# re-run to update citations
keys <- rbbt::bbt_detect_citations(path="ch2_main.qmd")
ignore <- c("^fig-", "^tbl-", "^sec-")
for (pt in ignore) {
  keys <- grep(pt, keys, invert = TRUE, value = TRUE)
}
rbbt::bbt_write_bib(keys=keys, path='references.bib', overwrite = TRUE, library_id=rbbt::bbt_library_id('CSAFE'), translator = "bibtex")
```





\ifnum \ifinstruction=1
\noindent \textcolor{gray}{Please note: Abbreviations should be introduced at the first mention in the main text – no abbreviations lists or tables should be included. Structure of the main text is provided below.}
\fi



# Background \& Summary {#sec-background-summary .unnumbered}


<!-- Source Problem-->
An important part of a forensic analysis is the investigation of marks left at a crime scene. Forensic examiners are in particular interested in the origin of those marks, ie. in the investigation of their source.  This is known as the Source Identification Problem in Forensic Science \hh{citation?}. The forensic science community generally distinguishes between the **specific source problem**, where the examiner is interested in whether a mark was left by a specific tool, and  **the common source problem**, where the focus of the investigation is on whether two marks were left by the same tool. Current accepted practice in both of these situations is based on a visual inspection of the items under a comparison microscope and results, according to the Theory of Identification [@afte] developed by the Association of Firearm and Toolmark Examiners (AFTE), in a conclusion of the form *identification* (the marks are believed to have been made by the same source), *elimination* (the marks on the two items are believed to have been made by different tools), and *inconclusive* (there are not enough similiarities or dissimilarities between the marks to allow either an identification or an elimination). At its core, this assessment is subjective in its nature and has been criticized in reports by the National Research Council [@nas2009] and the President's Council of Advisors on Science and Technology [@pcast] for its lack of objectivity and the absence of error rates. 

<!-- We need data to address both of these issues -->
Both of these issues rely on data with known ground-truth. 

\hh{Biedermann}[@biedermannStrangePersistenceSource2022] \hh{distinguishes between internal and external perspectives in the forensic literature. The external perspective only allows general statements based on (black-box) studies relating examiners' conclusions to ground truth without considering any evidence of a particular case. To allow an internal perspective, there is a need to quantitatively capture  the basis for an evaluation based on specific evidence.   }




When a bladed tool cuts a wire, striation marks are left on the cut surface of the wire, as shown in @fig-cut-microscope.


```{r}
#| echo: false
#| out.width: "400px"
#| out.height: "300px"
#| label: fig-cut-microscope
#| fig-cap: Microscopic close-up of striations left by a blade on the cut end of a wire.
knitr::include_graphics("images/IMG_72116.jpg")
```


Wire cut data is a type of forensic tool mark data used to identify the source of a wire cutter based on the striations left on the surface.
There have been cases where the evidence and testimony on wire cut evidence played a crucial role in the criminal investigation and conviction of a defendant.

However,
there is a lack of a standardized method to analyze it,
except for visual comparison. 

<!-- previous research -->
Work on striations made by screwdrivers[@baikerQuantitativeComparisonStriated2014] identified angle of attack[@baikerToolmarkVariabilityQuality2015a], rotational axis[@garciaInfluenceAxialRotation2017], and direction[@cuellarAlgorithmForensicToolmark2024] as the main factors for comparisons. 



<!-- collect data -->
Earlier research by Ma et al. [@maNISTBulletSignature2004] and Zheng et al. [@zhengNISTBallisticsToolmark2016] has focused on collecting and distributing datasets for this purpose and providing a foundation for future advancements in tool mark analysis.
Studies such as those by Chu et al. [@chuAutomaticIdentificationBullet2013] and Vorburger et al. [@vorburgerApplicationsCrosscorrelationFunctions2011] have demonstrated the efficacy of using numerical methods to improve accuracy and consistency in tool mark analysis.
Hare et al. [@hareAutomaticMatchingBullet2017] and Ju et al. [@juJournalOpenSourceImplementation2022] have explored methods for quantifying the similarity between representative signals, but alignment remains a major hurdle.


In this study,
we would like to follow the same path and provide a data set of wire cut scans,
and also discuss a systematic pipeline to analyze the data and draw conclusions based on numerical measures.
Here,
we provide a data set containing multiple files,
as described in @tbl-data-overview.


```{r}
#| echo: FALSE
#| label: tbl-data-overview
#| tbl-cap: Structure of available data and files.
#| results: asis

gt_table <- tibble(
  group_type = c(rep("Raw data", 2), rep("Manual derivatives", 1), rep("Computational derivatives in folder 'data-derived/'", 2), rep("Image files", 2), "Visual Inventory in folder 'assessment/analysis-manual/'"),
  data_type = c("`scans/`", "`meta.csv`", "`profiles/`", "`wire-signals`", "`wire_pairwise_ccf`", "`pngs/`", "`profile-images/`", "`processing-wires`"),
  Description = c("folder containing 120 topographic 3d scans corresponding to 30 aluminum wire cuts (x3p format)", "meta information for each cut with tool, blade, and location information (CSV format)", "folder of files with manually extracted profiles (CSV format)", "signals processed from corresponding profile (zipped CSV format)", "CCF values of all pairwise aligned signals (zipped CSV format)", "folder containing pictures of 3d scans of wire cuts (PNG format)", "folder containing pictures of profile extracted from wire cuts (PNG format)", "display of pairwise aligned signals from the same sources (HTML format)"),
  Section = c("[Cutting Wires](#sec-cutting-wires)", "[Cutting Wires](#sec-cutting-wires)", "[Extract Profiles](#sec-extract-profiles)", "[Filtered Signals](#sec-filtered-signals)", "[Align Signals](#sec-align-signals)", "[Cutting Wires](#sec-cutting-wires)", "[Extract Profiles](#sec-extract-profiles)", "[Align Signals](#sec-align-signals)")
) %>% group_by(group_type) %>%
  gt(rowname_col = "data_type") %>%
  tab_options(table.width = pct(97)) %>%
  cols_width(data_type~ pct(25), Description ~ pct(60), Section~pct(15), everything() ~ pct(20)) %>%
  fmt_markdown() 
# gt_table contains the markdown version of the table the way it is supposed to look.
# the errors get introduced in the as_latex function

string <- gt_table %>% as_latex()

# # column widths code - start
# # has bug: column Description is not being recognized, last section is the widest
# # bug fix: it seems, that this is a shift in the column numbers: 
# # - description width is controlled by data_type.
# # - Section width is controlled by Description. 
dimexprs <- str_extract_all(pattern = "dimexpr 0.[0-9]+", string[1])[[1]]
# the dimension expressions have now changed to 
# "dimexpr 0.19" "dimexpr 0.24" "dimexpr 0.58"
# replace these with 
replacement = paste("dimexpr", c(0.26, 0.56, 0.18))
string[1] <- str_replace_all(pattern = "dimexpr 0.[0-9]+", replacement = "dimexpr FIX", string[1])
# replace one by one
for (i in seq_along(dimexprs)) {
  string[1] <- str_replace(string[1], "dimexpr FIX", replacement[i])
}
# column width - end


# fixing cross-references - start
crossrefs <- str_extract_all(pattern = "hyperlink\\{[^ {]*\\}\\{.*\\}", string[1])[[1]]
# now replace every one of these cross references with the Latex call to autoref
crossrefs <- unique(crossrefs) # only needed once
# crossrefs <- crossrefs[nchar(crossrefs) > 1] # and only real references need to be dealt with
cross_latex <- crossrefs %>%
  str_replace("\\{", "[") %>%
  str_replace("\\}", "]") %>%
  str_replace("hyperlink", "\\\\hyperref")

string2 <- string[1]
for (i in seq_along(crossrefs)) {
  string2 <- str_replace_all(string2, crossrefs[i] %>%
    str_replace_all("\\{", "\\\\{") %>%
    str_replace_all("\\}", "\\\\}"), cross_latex[i])
}
string[1] <- string2
# fixing cross-references - end

string
```

For the reproducibility of all our data and alignment results,
we introduce in detail in [Cutting Wires](#sec-cutting-wires) \tom{hyperlink location incorrect for unnumbered sections}\hh{it seems that the hyperlinks make sure that the section is on the page} how we cut the wire and collect the 120 scans with 5 tools,
in [Extract Profiles](#sec-extract-profiles) how we extract profiles from the scans,
in [Filtered Signals](#sec-filtered-signals) how we filter signals from the profiles,
in [Align Signals](#sec-align-signals) how we align signals from different scans and optimize the alignment with the cross-correlation function (CCF) values.
In [Data Records](#sec-data-records),
we discuss where our data is held.
Then,
in [Technical Validation](#sec-technical-validation),
a technical validation was conducted to further compare signals from different sources also match our assumption,
together with visual aids for drawing conclusions.
Finally,
in [Usage Notes](#sec-usage-notes),
we provide available codes for creating the data set and conducting technical validation,
as discussed in [Methods](#sec-methods) and [Technical Validation](#sec-technical-validation). [Code availability](#sec-code-availability) discusses where these codes can be found online.
We hope this pipeline developed using this data set can be further generalized and applied to real crime scenes to help investigators draw conclusions based on real wire cut data.


\ifnum \ifinstruction=1
\textcolor{gray}{(unlimited length) An overview of the study design, the assay(s) performed, and the created data, including any background information needed to put this study in the context of previous work and the literature. The section should also briefly outline the broader goals that motivated the creation of this dataset and the potential reuse value. We also encourage authors to include a figure that provides a schematic overview of the study and assay(s) design. The Background \& Summary should not include subheadings. This section and the other main body sections of the manuscript should include citations to the literature as needed.}
\fi



# Methods {#sec-methods .unnumbered}

In this study,
aluminum wire was used to create an optimal scenario where the most amount of information could be transferred from the tool to the substrate despite the wire,
in some real cases,
being made of lead. 
The physical property of aluminum wire makes it an excellent candidate for keeping marks while being relatively easy to bend and non-toxic.


## Cutting Wires {#sec-cutting-wires .unnumbered}

The aluminum wire used was 16 Gauge/1.5 mm, anodized.
In order to cut the wire,
4-inch pieces were unspooled and cut using Kaiweets wire cutters,
model KWS-105,
as shown in @fig-plier-tip,
for 1 blade location,
either inner, middle, or outer,
which gives us 1 replicate.
Each piece was then cut into half to create 2-inch pieces for each side,
AB and CD,
with a sharpie line marking the cut ends,
giving us 4 samples.
Then,
we can use the standard scanning protocols for the confocal microscope,
shown in Figure @fig-wire-microscope,
to scan the wire tip surfaces.
The scanned surfaces are saved in a resolution of $0.645 \mu m \times 0.645 \mu m$ per square pixel in an \texttt{x3p} file format.
Here,
we are showing AB and CD sides in @fig-T1AW-LI-R2-4edges,
with the back of A being C and the back of B being D.
Both AB and CD sides form tent structures on the tips of the wire,
and we can separate each side of the tent into 2 pieces along the bending position,
resulting in 8 scans.
We repeated this process for all 3 locations along the blade and 5 wire cutters,
with 2 replicates for each tool-edge-location combination,
resulting in 120 scans.
Each piece was labeled with the naming conventions,
T(ool) 1/2/3/4/5 (Edge) A/B/C/D W(ire) - L(ocation) I(nner)/M(iddle)/O(uter) -  R(epetition) 1/2,
with T1AW-LI-R1 being the piece cut by tool 1 on the A edge at the inner location for the first repetition.


:::: {#fig-cut-tent-scan layout="[30, -5, 65]"}

:::{}

![](images/plier-tip.png){#fig-plier-tip height=15%}

![](images/wire-microscope-062524.JPG){#fig-wire-microscope height=15%}

:::

:::{}
![](images/T1AW-LI-R2-4edges.png){#fig-T1AW-LI-R2-4edges height=33%}
:::

\(a) A Kaiweets wire cutter of model KWS-105 was used to cut the wire, with inner, middle and outer locations marked. (b) A confocal microscope was used to scan the wire surfaces. (c) After separating 2 tent structures by the connecting position, we obtained 4 samples - 2 samples from blade A and B, and others from blade C and D. \tom{width and height are tuned manually} \tom{ | full requirements see \href{https://www.nature.com/sdata/publish/submission-guidelines\#figures}{https://www.nature.com/sdata/publish/submission-guidelines\#figures}}

::::


## Extract Profiles {#sec-extract-profiles .unnumbered}

Numerical comparisons between 2 replicates cannot be done directly on the \texttt{x3p} files.
We need to extract representative functions from the scans first.
A representative function with the most information is considered as a signal for one scan,
which can be used later for comparison.
To obtain this function,
we first need a profile of the scan,
which is a sequence of values along a user-drawn line on the surface.
The profile should capture most features of the scan and be orthogonal to the striation marks of the scan,
which are formed by the ups and downs of grooves.
So,
we draw the line across the wide region of the scan to maximize the feature captured,
as shown in dark blue in @fig-T1AW-LI-R1-profiles.
We can then investigate the values under this profile line.
The profile function along the line is plotted in @fig-T1AW-LI-R1-profiles-plot.


## Filtered Signals {#sec-filtered-signals .unnumbered}

With the profile extracted,
we can then obtain the signal.
Two Gaussian filters,
as discussed in Cleveland et al. [@clevelandLocalRegressionModels1992],
are applied to these resulting profiles.
In particular,
we first used a large low-pass filter with bandwidths of 400 microns to remove the large trend,
as it can overwhelm the signals,
and then used a small high-pass filter of 40 microns to average across noise and remove spikes,
as shown in @fig-T1AW-LI-R1-signals-plot.
\hh{(add reference: W. S. Cleveland, E. Grosse and W. M. Shyu (1992) Local regression models. Chapter 8 of Statistical Models in S eds J.M. Chambers and T.J. Hastie, Wadsworth \& Brooks/Cole.)}.
Finally,
the extreme tail values are removed.


:::: {#fig-T1AW-LI-R1-profiles-signals layout="[1, 1]"}

:::{}

![](images/T1AW-LI-R1-profiles.png){#fig-T1AW-LI-R1-profiles height=28%}

:::

:::{}

![](images/T1AW-LI-R1-profiles-plot.png){#fig-T1AW-LI-R1-profiles-plot height=13%}

![](images/T1AW-LI-R1-signals-plot.png){#fig-T1AW-LI-R1-signals-plot height=13%}
:::

\(a) A profile line in dark blue was drawn across the striations of the scan. (b) The profile function extracted along the profile line in (a). (c) The raw signal in light blue is obtained by using the low-pass filter on the profile function in (b) and the filtered signal is obtained by using the high-pass filter on the raw signal.

::::


## Align Signals {#sec-align-signals .unnumbered}

Signals extracted from different scans can be put together for comparison,
and we maximize the cross-correlation function (CCF) values between the signals to find the best alignment numerically.
For example,
we compare T1AW-LI-R1 to T1AW-LI-R2,
T1CW-LI-R1 to T1CW-LI-R2,
and so on.
That is comparing each row in Figure \ref{fig-scans-pair}.
We know that signals from two replicates with the same tool-edge-location combination should yield similar signals，
as in the first and second columns of Figure \ref{fig-signals-pair-alignment},
which will give alignments of massive overlapping and high CCF values close to 1.
The alignments and values we got in the rightmost column of Figure \ref{fig-signals-pair-alignment} fulfill our expectations.


```{r}
#| echo: false
#| out.width: "600px"
#| out.height: "750px"
#| label: fig-scans-pair
#| fig-cap: Scans from different sides of tool 1 at the inner location.
knitr::include_graphics("images/scans_pair.png")
```


```{r}
#| echo: false
#| out.width: "500px"
#| out.height: "350px"
#| label: fig-signals-pair-alignment
#| fig-cap: The first and second columns show the signals extracted from Figure \ref{fig-scans-pair}, and the third column shows the alignments and CCF values between pairs of signals.
knitr::include_graphics("images/signals_pair_alignment.png")
```


\ifnum \ifinstruction=1
\textcolor{gray}{(unlimited length) The Methods should include detailed text describing any steps or procedures used in producing the data, including full descriptions of the experimental design, data acquisition assays, and any computational processing (e.g. normalization, image feature extraction). See the detailed section in our submission guidelines for advice on writing a transparent and reproducible methods section. Related methods should be grouped under corresponding subheadings where possible, and methods should be described in enough detail to allow other researchers to interpret and repeat, if required, the full study. Specific data outputs should be explicitly referenced via data citation (see Data Records and Citing Data, below).}

\textcolor{gray}{Authors should cite previous descriptions of the methods under use, but ideally the method descriptions should be complete enough for others to understand and reproduce the methods and processing steps without referring to associated publications. There is no limit to the length of the Methods section. Subheadings should not be numbered.}

\textcolor{gray}{Authors should review the transparent methods checklist below, and ensure that their manuscript complies with any relevant points. Authors are also encouraged to search FAIRsharing.org for community reporting standards that may be relevant to their specific data-type.}

Transparent Methods Checklist
\begin{itemize}
  \item
  Materials \& reagents:
  Identify commercial suppliers of reagents, instrumentation or kits, when the source is critical to the outcome of the experiments.
  Declare any restrictions on the availability of unique materials (more information here).
  Provide catalogue or clone numbers for all antibodies (if available). For primary antibodies, provide proof of validation for the relevant species and applications.
  
  \item
  Exclusion criteria: If any data or samples were excluded, explain the exclusion criteria and state in the methods whether the criteria were established before the study was conducted.
  
  \item
  Randomization \& blinding: For any studies that involve assigning samples, animals or participants into different groups:
  State clearly whether randomization methods were used. If randomization was not employed, this should be clearly stated.
  State clearly whether blinding was employed during data collection. If blinding was not employed, this should be clearly stated.
  
  \item
  Animal \& human studies (full journal policies here):
  Experiments involving human participants must identify the committee approving the experiments, and include a statement confirming that informed consent was obtained from all participants.
  Studies employing nonhuman animals should ensure that methods descriptions comply with the ARRIVE checklist.
  
  \item
  Cell lines:
  For each eukaryotic cell line used, state the source and whether the cell line has been authenticated or otherwise tested for integrity.
  If any commonly misidentified cell lines were used (see ICLAC or NCBI Biosample), justify their use.
  Report whether the cell lines were tested for mycoplasma contamination.
  
  \item
  Chemistry \& materials science: Manuscripts describing chemical syntheses, or characterizing new chemicals or materials should refer to the guidance at Nature Chemistry.
  
\end{itemize}
\fi


<!-- \subsection*{Subsection} -->

<!-- Example text under a subsection. Bulleted lists may be used where appropriate, e.g. -->

<!-- \begin{itemize} -->
<!-- \item First item -->
<!-- \item Second item -->
<!-- \end{itemize} -->

<!-- \subsubsection*{Third-level section} -->

<!-- Topical subheadings are allowed. -->



# Data Records {#sec-data-records .unnumbered}

The complete data set is available on the ISU DataShare repository at \href{https://iastate.figshare.com/}{https://iastate.figshare.com/},
which is public and open access for every interested researcher.
The structure of the data set is described before in @tbl-data-overview.


\ifnum \ifinstruction=1
\textcolor{gray}{(unlimited length) The Data Records section should be used to explain each data record associated with this work, including the repository where this information is stored, and to provide an overview of the data files and their formats. Each external data record should be cited numerically in the text of this section, for example \cite{Hao:gidmaps:2014}, and included in the main reference list as described below. A data citation should also be placed in the subsection of the Methods containing the data-collection or analytical procedure(s) used to derive the corresponding record. Providing a direct link to the dataset may also be helpful to readers (\hyperlink{https://doi.org/10.6084/m9.figshare.853801}{https://doi.org/10.6084/m9.figshare.853801}).}

\textcolor{gray}{Tables should be used to support the data records, and should clearly indicate the samples and subjects (study inputs), their provenance, and the experimental manipulations performed on each (please see 'Tables' below). They should also specify the data output resulting from each data-collection or analytical step, should these form part of the archived record.}
\fi



# Technical Validation {#sec-technical-validation .unnumbered}

For the data collection process,
two team members did the cutting and labeling together,
then one person did the scanning and named according to the naming convention above. The scanning was done in a specific order to ensure consistency across all scans.
The data was saved in a consistent format to ensure they could be easily accessed and analyzed.
A third person then checked the data to ensure that the data was consistent in naming and accurate.

For the validation of the scans and their processing,
we investigate the correlation scores of pairwise aligned signals. Large scores between signals are indicative of being made by the same tool. As shown previously in Figure \ref{fig-signals-pair-alignment} in [Align Signals](#sec-align-signals), we would expect a high correlation score between signals from scans of wires cut with the same tool. For signals from scans of wires cut with a different tool, we would expect a low correlation score. For example, we have two scans from different tools, T1AW-LI-R1 and T2AW-LI-R1, as shown in @fig-T1AW-LI-R1 and @fig-T2AW-LI-R1. The alignment is shown in @fig-T1AW-LI-R1-T2AW-LI-R1 with a 0.2 CCF value, which is low, as expected.

We also put resulting CCFs for all pairwise comparisions in the boxplot,
together with the receiver operating characteristic (ROC) curve,
as in Figure \ref{fig-ccf-boxplot} and Figure \ref{fig-ccf-ROC}.
We can see that the CCF values for the same sources are close to 1,
while the CCF values for different sources are much lower than expected.
This is consistent with our expectations and validates our data processing pipeline.


::: {#fig-T1AW-LI-R1-T2AW-LI-R1-alignment layout="[[1, 1], [-0.5, 9, 0.5]]"}

![](images/T1AW-LI-R1.png){#fig-T1AW-LI-R1 height=5.5cm}

![](images/T2AW-LI-R1.png){#fig-T2AW-LI-R1 height=5.5cm}

![](images/T1AW-LI-R1-T2AW-LI-R1.png){#fig-T1AW-LI-R1-T2AW-LI-R1 height=5cm}

\(a) Scan T1AW-LI-R1 cut by tool 1. (b) Scan T2AW-LI-R1 cut by tool 2. (c) Alignment of signals from T1AW-LI-R1 and T2AW-LI-R1.

:::


```{r}
#| echo: false
#| out.width: "650px"
#| out.height: "300px"
#| label: fig-ccf-boxplot
#| fig-cap: The boxplot shows that signals from the same sources have higher CCfs than those from different sources.
knitr::include_graphics("images/ccf_boxplot.png")
```


```{r}
#| echo: false
#| out.width: "500px"
#| out.height: "500px"
#| label: fig-ccf-ROC
#| fig-cap: The ROC curve is bending very close to the upper left corner, which means excellent in classification and drawing conclusions.
knitr::include_graphics("images/ccf_ROC.png")
```


\ifnum \ifinstruction=1
\textcolor{gray}{(unlimited length) This section presents any experiments or analyses that are needed to support the technical quality of the dataset. This section may be supported by figures and tables, as needed. This is a required section; authors must present information justifying the reliability of their data.}

\begin{itemize}
  \item
  Measurement of data quality?
  
  \begin{itemize}
    \item
    Numeric measurements / tests: ?
    
    \item
    Visualizations: ?
    
    \item
    Check with existing data: ?
    
    \item
    Questionable / slur procedures:
      
      \begin{itemize}
      \item
      \href{https://www.nature.com/articles/s41597-024-03341-w?_gl=1*5ya8g2*_up*MQ..&gclid=EAIaIQobChMInOXO84DVhgMViewWBR3vWQJAEAAYASAAEgJICfD_BwE#Sec28}{AidData’s Geospatial Global Chinese Development Finance Dataset}: \textcolor{gray}{Second, all data collected is reviewed by at least two individuals. Although this is not a double-blind review procedure, the use of satellite imagery to verify project locations results in far less uncertainty when compared to previous approaches to geocoding where locations were selected entirely based on text descriptions.}
      
      \item
      \href{https://www.nature.com/articles/s41597-024-03021-9?_gl=1*1u1zppx*_up*MQ..&gclid=EAIaIQobChMInOXO84DVhgMViewWBR3vWQJAEAAYASAAEgJICfD_BwE#Sec9}{A large open access dataset of brain metastasis 3D segmentations on MRI with clinical and imaging information}: \textcolor{gray}{A medical student (D.R.) double checked and adjusted the revised NIfTI segmentation masks and manually counted the number of lesions with contrast-enhancement, necrosis, and peritumoral edema for each patient.}
      
      \item
      \href{https://www.nature.com/articles/s41597-024-03445-3?_gl=1*1ikco52*_up*MQ..&gclid=EAIaIQobChMInOXO84DVhgMViewWBR3vWQJAEAAYASAAEgJICfD_BwE#Sec11}{Time series of freshwater macroinvertebrate abundances and site characteristics of European streams and rivers}: \textcolor{gray}{Technical validation of the TREAM dataset was achieved through exclusion of time series data that did not match our inclusion criteria and data standardisation steps (outlined in Methods above). Any noted issues that did not adhere to the outlined standardisation within the datasets from the 41 independent projects included in this dataset were checked with data providers and corrected or removed when standardisation was not achievable (e.g., when collection methods changed over the course of the time series).}
      
      \item
      \href{https://www.nature.com/articles/s41597-023-02684-0?_gl=1*1t69zgo*_up*MQ..&gclid=EAIaIQobChMInOXO84DVhgMViewWBR3vWQJAEAAYASAAEgJICfD_BwE#Sec12}{3D surgical instrument collection for computer vision and extended reality}: \textcolor{gray}{The main issue...Since we store our models in a standard format (STL), they are compatible with a large variety of visualisation and processing software.}
      
      \item
      \href{https://www.nature.com/articles/s41597-024-03396-9?_gl=1*1ikco52*_up*MQ..&gclid=EAIaIQobChMInOXO84DVhgMViewWBR3vWQJAEAAYASAAEgJICfD_BwE#Sec4}{Three-dimensional reconstruction of high latitude bamboo coral via X-ray microfocus Computed Tomography
}: \textcolor{gray}{Regular quality assurance inspections are carried out on the µ-CT scanner to verify its metrological and geometrical (alignments) accuracy for conducting the scans. The geometry of source to object and source to detector distances are verified whenever there is any significant physical interaction with the source such as re-alignment, change of filament, or source anode change. This calibration process involves scanning a specially designed phantom known as an ‘hourglass’36, which consists of three pairs of high-sphericity spheres. The sphere sizes are as follows: two spheres with a diameter of 3.000 mm, two spheres with a diameter of 6.000 mm, and two spheres with a diameter of 9.525 mm, and each sphere is kept in contact with its size-counterpart. By using this phantom, it becomes possible to accurately determine a known distance, specifically the centre-to-centre distance of the spheres, in a threshold-independent manner. If the measured distance deviates beyond the acceptable limits of metrological accuracy, the system’s calibration parameters are adjusted to ensure agreement between the measured distance and the actual distance.}
      
      \end{itemize}
      
    \end{itemize}
  
\end{itemize}
\fi



# Usage Notes {#sec-usage-notes .unnumbered}

The \texttt{R} package \texttt{x3ptools}[@hofmannX3ptoolsToolsWorking2018] available from \texttt{CRAN} supports working with files in \texttt{x3p} format. The sample scripts in \texttt{R} for processing scans from \texttt{x3p} format to their signal and alignment are available on \texttt{GitHub} [heike/wirecuts-data](https://github.com/heike/wirecuts-data) in the `assessment/code` folder, as described in @tbl-code-overview.


```{r}
#| echo: FALSE
#| label: tbl-code-overview
#| tbl-cap: Overview of available codes.
#| results: asis

string <- tibble(
  group_type = c(rep("Inspect raw scans", 1), rep("Extract profiles", 2), rep("Derive signals", 1), rep("Align signals", 3)),
  code_type = c("`1-create_pngs_from_x3p.R`", "`2-create_profiles_from_x3p.R`", "`3-create-single-profile-file.R`", "`4-create_signals_from_profiles.R`", "`5-create-images.R`", "`6-align-pairwise.R`", "`7-all-comparison-results.R`"),
  Description = c("obtain images of `x3p`s in `scans/`", "manually extract profiles from each scan", "create meta profile information", "derive signals from each profile", "create images for pairwise alignment", "compute pairwise alignment CCF values", "visualize comparison results"),
  Section = c("[Cutting Wires](#sec-cutting-wires)", "[Extract Profiles](#sec-extract-profiles)", "[Extract Profiles](#sec-extract-profiles)", "[Filtered Signals](#sec-filtered-signals)", "[Align Signals](#sec-align-signals)", "[Align Signals](#sec-align-signals)", "[Align Signals](#sec-align-signals)")
) %>%
  gt(rowname_col = "code_type", groupname_col = "group_type") %>%
  tab_options(table.width = pct(95)) %>%
  cols_width(Description ~ pct(45), Section ~ pct(30), everything() ~ pct(55)) %>%
  fmt_markdown() %>%
  as_latex()

# column widths code - start
# has bug: column Description is not being recognized, last section is the widest
widths <- str_extract_all(pattern = "dimexpr.....", string[1])[[1]]
# change into the right order
widths_new <- widths[c(1, 3, 2)]

# replace all instances to something strange
string2 <- str_replace_all(string[1], "dimexpr....", "dimexprSMALL")
# now replace (one at a time, otherwise we have a problem)
string2 <- str_replace(string2, "dimexprSMALL", widths_new[1])
string2 <- str_replace(string2, "dimexprSMALL", widths_new[2])
string2 <- str_replace(string2, "dimexprSMALL", widths_new[3])

string[1] <- string2
# column widths code - end

# fixing cross-references - start
crossrefs <- str_extract_all(pattern = "hyperlink\\{[^ {]*\\}\\{.*\\}", string[1])[[1]]
# now replace every one of these cross references with the Latex call to autoref
crossrefs <- unique(crossrefs) # only needed once
# crossrefs <- crossrefs[nchar(crossrefs) > 1] # and only real references need to be dealt with
cross_latex <- crossrefs %>%
  str_replace("\\{", "[") %>%
  str_replace("\\}", "]") %>%
  str_replace("hyperlink", "\\\\hyperref")

string2 <- string[1]
for (i in seq_along(crossrefs)) {
  string2 <- str_replace_all(string2, crossrefs[i] %>%
    str_replace_all("\\{", "\\\\{") %>%
    str_replace_all("\\}", "\\\\}"), cross_latex[i])
}
string[1] <- string2
# fixing cross-references - end

string
```


We already conduct pairwise comparisons and visualize some of the comparison results in [Align Signals](#sec-align-signals) and [Technical Validation](#sec-technical-validation),
and we can also produce other analysis plots.

Suppose we put the CCF values in a tilemap with different tools, locations and edge combinations.
In that case,
we expect only the diagonal to have high CCF values,
close to 1 and marked as orange in the tilemap,
as the diagonal represents the same source,
and the rest of the matrix to have low CCF values,
close to 0 and marked as gray.
In Figure \ref{fig-ccf-tilemap},
the behavior is consistent with our expectation overall,
except for some rare cases with tool 5 edge D.
The density plot in Figure \ref{fig-ccf-density} shows the distribution of the CCF values with the same sources and different sources.
The overlapping points between the tails of these two distributions can be a rough threshold.

Furthermore,
the ROC curve in Figure \ref{fig-ccf-ROC} shows the sensitivity / true positive rate against the false positive rate (FPR) (1 - specificity).
The curve is very close to the upper left corner,
which is excellent for classification and drawing conclusions.
It gives us a true threshold of 0.589 to control the FPR to be less than 0.05 with a false negative rate (FNR) to be 0,
\tom{(false positive rate (FPR) / false discovery rate (FDR) -> define the H0 or call it false identification rate (FIR)???)},
and 0.658 to control the FPR to be less than 0.01,
with FNR to be 0.02.


```{r}
#| echo: false
#| out.width: "600px"
#| out.height: "400px"
#| label: fig-ccf-tilemap
#| fig-cap: The tilemap shows signals from the same source have CCFs close to 1.
knitr::include_graphics("images/ccf_tilemap.png")
```


```{r}
#| echo: false
#| out.width: "500px"
#| out.height: "250px"
#| label: fig-ccf-density
#| fig-cap: The density plot shows tails of distributions overlap, which can be used as a rough threshold for drawing conclusions.
knitr::include_graphics("images/ccf_density.png")
```


\ifnum \ifinstruction=1
\textcolor{gray}{(unlimited length) The Usage Notes should contain brief instructions to assist other researchers with reuse of the data. This may include discussion of software packages that are suitable for analysing the assay data files, suggested downstream processing steps (e.g. normalization, etc.), or tips for integrating or comparing the data records with other datasets. Authors are encouraged to provide code, programs or data-processing workflows if they may help others understand or use the data. Please see our code availability policy for advice on supplying custom code alongside Data Descriptor manuscripts.}

\textcolor{gray}{For studies involving privacy or safety controls on public access to the data, this section should describe in detail these controls, including how authors can apply to access the data, what criteria will be used to determine who may access the data, and any limitations on data use.} 
\fi



# Code availability {#sec-code-availability .unnumbered}


We made available all codes we used for inspecting raw scans, extracting profiles, derving signals, aligning signals, and visualizing comparison results discussed in [Methods](#sec-methods) and [Technical Validation](#sec-technical-validation), as described in @tbl-code-overview. All results are reproducible using these codes provided.


\ifnum \ifinstruction=1
\textcolor{gray}{For all studies using custom code in the generation or processing of datasets, a statement must be included under the heading "Code availability", indicating whether and how the code can be accessed, including any restrictions to access. This section should also include information on the versions of any software used, if relevant, and any specific variables or parameters used to generate, test, or process the current dataset.}
\fi





